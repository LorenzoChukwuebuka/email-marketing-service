package contentanalysis

import (
	"context"
	"encoding/json"
	"fmt"
	"math"
	"os"
	"regexp"
	"strings"
	"sync"

	"github.com/pkg/errors"
	"go.uber.org/zap"
	"github.com/jdkato/prose/v2"
	"github.com/bbalet/stopwords"
	"gonum.org/v1/gonum/stat"
	"github.com/cdipaolo/sentiment"
)

// NLPContentAnalyzer represents the main structure for NLP-based content analysis
type NLPContentAnalyzer struct {
	config         *NLPConfig
	logger         *zap.Logger
	model          *prose.Model
	sentimentModel sentiment.Models
	urlRe          *regexp.Regexp
	emailRe        *regexp.Regexp
}

// NLPConfig holds all the configuration parameters for the NLP content analyzer
type NLPConfig struct {
	SpamThreshold     float64            `json:"spam_threshold"`
	SensitiveEntities []string           `json:"sensitive_entities"`
	TopicKeywords     map[string][]string `json:"topic_keywords"`
	ImageExtensions   []string           `json:"image_extensions"`
	LanguageModel     string             `json:"language_model"`
	MaxLinks          int                `json:"max_links"`
	MaxEmails         int                `json:"max_emails"`
}

// NLPAnalysisResult represents the outcome of NLP-based content analysis
type NLPAnalysisResult struct {
	IsSafe           bool
	Message          string
	SpamScore        float64
	SentimentScore   float64
	TopicRelevance   map[string]float64
	SensitiveContent bool
	Entities         []string
	LinkCount        int
	EmailCount       int
}

// NewNLPContentAnalyzer creates a new instance of NLPContentAnalyzer
func NewNLPContentAnalyzer(configPath string, logger *zap.Logger) (*NLPContentAnalyzer, error) {
	// Load configuration from file
	config, err := loadNLPConfig(configPath)
	if err != nil {
		return nil, errors.Wrap(err, "failed to load config")
	}

	// Load the language model
	model, err := prose.UDPipeModel(prose.LanguageToCode(config.LanguageModel))
	if err != nil {
		return nil, errors.Wrap(err, "failed to load language model")
	}

	// Initialize sentiment model
	sentimentModel, err := sentiment.Restore()
	if err != nil {
		return nil, errors.Wrap(err, "failed to initialize sentiment model")
	}

	// Compile regular expressions for URLs and email addresses
	urlRe := regexp.MustCompile(`https?://\S+`)
	emailRe := regexp.MustCompile(`\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b`)

	return &NLPContentAnalyzer{
		config:         config,
		logger:         logger,
		model:          model,
		sentimentModel: sentimentModel,
		urlRe:          urlRe,
		emailRe:        emailRe,
	}, nil
}

// loadNLPConfig reads and parses the JSON configuration file
func loadNLPConfig(path string) (*NLPConfig, error) {
	file, err := os.ReadFile(path)
	if err != nil {
		return nil, err
	}

	var config NLPConfig
	if err := json.Unmarshal(file, &config); err != nil {
		return nil, err
	}

	return &config, nil
}

// AnalyzeContent performs NLP-based content analysis on the given text and attachments
func (nca *NLPContentAnalyzer) AnalyzeContent(ctx context.Context, text string, attachments []string) (NLPAnalysisResult, error) {
	var (
		wg     sync.WaitGroup
		result NLPAnalysisResult
		mu     sync.Mutex
	)

	result.TopicRelevance = make(map[string]float64)

	// Analyze text content
	wg.Add(5)
	go func() {
		defer wg.Done()
		result.SpamScore = nca.calculateSpamScore(text)
	}()
	go func() {
		defer wg.Done()
		result.SentimentScore = nca.analyzeSentiment(text)
	}()
	go func() {
		defer wg.Done()
		nca.analyzeTopicRelevance(text, &result, &mu)
	}()
	go func() {
		defer wg.Done()
		nca.detectSensitiveContent(text, &result, &mu)
	}()
	go func() {
		defer wg.Done()
		nca.analyzeLinks(text, &result, &mu)
	}()

	// Analyze attachments
	wg.Add(1)
	go func() {
		defer wg.Done()
		nca.analyzeAttachments(attachments, &result, &mu)
	}()

	// Wait for all analyses to complete
	wg.Wait()

	// Determine if the content is safe based on the analysis results
	result.IsSafe = result.SpamScore < nca.config.SpamThreshold && !result.SensitiveContent

	// Generate a summary message
	result.Message = nca.generateSummaryMessage(&result)

	return result, nil
}

// calculateSpamScore uses TF-IDF and other metrics to estimate the likelihood of spam
func (nca *NLPContentAnalyzer) calculateSpamScore(text string) float64 {
	doc, _ := nca.model.Annotate(text)

	// Calculate TF-IDF
	termFreq := make(map[string]float64)
	for _, token := range doc.Tokens() {
		if token.Tag != "PUNCT" {
			termFreq[strings.ToLower(token.Text)]++
		}
	}

	tfidfScores := make([]float64, len(termFreq))
	i := 0
	for _, freq := range termFreq {
		tf := freq / float64(len(doc.Tokens()))
		idf := math.Log(1 + 1/freq) // Simplified IDF calculation
		tfidfScores[i] = tf * idf
		i++
	}

	// Use the variance of TF-IDF scores as a spam indicator
	// Higher variance might indicate more diverse, legitimate content
	variance := stat.Variance(tfidfScores, nil)
	spamScore := 1 / (1 + variance) // Normalize to [0, 1], where higher means more likely to be spam

	// Consider other factors (e.g., presence of URLs, unusual punctuation)
	urlCount := len(nca.urlRe.FindAllString(text, -1))
	exclamationCount := strings.Count(text, "!")
	
	spamScore += float64(urlCount) * 0.01 // Slight increase for each URL
	spamScore += float64(exclamationCount) * 0.005 // Slight increase for each exclamation mark

	return math.Min(spamScore, 1.0) // Ensure the score doesn't exceed 1
}

// analyzeSentiment performs sentiment analysis on the text
func (nca *NLPContentAnalyzer) analyzeSentiment(text string) float64 {
	analysis := nca.sentimentModel.SentimentAnalysis(text, sentiment.English)
	return float64(analysis.Score) / 5.0 // Normalize to [-1, 1]
}

// analyzeTopicRelevance determines how relevant the text is to predefined topics
func (nca *NLPContentAnalyzer) analyzeTopicRelevance(text string, result *NLPAnalysisResult, mu *sync.Mutex) {
	cleanedText := stopwords.CleanString(text, "en", true)
	words := strings.Fields(strings.ToLower(cleanedText))

	for topic, keywords := range nca.config.TopicKeywords {
		relevantWords := 0
		for _, word := range words {
			if contains(keywords, word) {
				relevantWords++
			}
		}
		relevance := float64(relevantWords) / float64(len(keywords))
		mu.Lock()
		result.TopicRelevance[topic] = relevance
		mu.Unlock()
	}
}

// detectSensitiveContent identifies potentially sensitive information in the text
func (nca *NLPContentAnalyzer) detectSensitiveContent(text string, result *NLPAnalysisResult, mu *sync.Mutex) {
	doc, _ := nca.model.Annotate(text)

	for _, ent := range doc.Entities() {
		for _, sensitiveType := range nca.config.SensitiveEntities {
			if ent.Label == sensitiveType {
				mu.Lock()
				result.SensitiveContent = true
				result.Entities = append(result.Entities, ent.Text)
				mu.Unlock()
				return
			}
		}
	}
}

// analyzeLinks counts and analyzes links in the text
func (nca *NLPContentAnalyzer) analyzeLinks(text string, result *NLPAnalysisResult, mu *sync.Mutex) {
	links := nca.urlRe.FindAllString(text, -1)
	emails := nca.emailRe.FindAllString(text, -1)

	mu.Lock()
	result.LinkCount = len(links)
	result.EmailCount = len(emails)
	mu.Unlock()

	if len(links) > nca.config.MaxLinks {
		mu.Lock()
		result.SpamScore += 0.1
		mu.Unlock()
	}

	if len(emails) > nca.config.MaxEmails {
		mu.Lock()
		result.SpamScore += 0.1
		mu.Unlock()
	}
}

// analyzeAttachments checks for suspicious attachments
func (nca *NLPContentAnalyzer) analyzeAttachments(attachments []string, result *NLPAnalysisResult, mu *sync.Mutex) {
	for _, filename := range attachments {
		for _, ext := range nca.config.ImageExtensions {
			if strings.HasSuffix(strings.ToLower(filename), ext) {
				mu.Lock()
				result.SpamScore += 0.05
				mu.Unlock()
				break
			}
		}
	}
}

// generateSummaryMessage creates a summary message based on the analysis results
func (nca *NLPContentAnalyzer) generateSummaryMessage(result *NLPAnalysisResult) string {
	if !result.IsSafe {
		if result.SpamScore >= nca.config.SpamThreshold {
			return fmt.Sprintf("Content flagged as potential spam (score: %.2f)", result.SpamScore)
		}
		if result.SensitiveContent {
			return fmt.Sprintf("Content contains sensitive information: %s", strings.Join(result.Entities, ", "))
		}
	}
	return fmt.Sprintf("Content appears safe (spam score: %.2f, sentiment: %.2f)", 
		result.SpamScore, result.SentimentScore)
}

// contains checks if a slice of strings contains a specific string
func contains(slice []string, item string) bool {
	for _, s := range slice {
		if s == item {
			return true
		}
	}
	return false
}

// Usage example
func main() {
	logger, _ := zap.NewProduction()
	defer logger.Sync()

	analyzer, err := NewNLPContentAnalyzer("nlp_config.json", logger)
	if err != nil {
		logger.Fatal("Failed to create NLP content analyzer", zap.Error(err))
	}

	ctx := context.Background()
	text := "Hello, let's meet for coffee at 3 PM to discuss the exciting project budget! Check out this link: http://example.com"
	attachments := []string{"document.pdf", "image.jpg"}

	result, err := analyzer.AnalyzeContent(ctx, text, attachments)
	if err != nil {
		logger.Error("Content analysis failed", zap.Error(err))
	} else {
		logger.Info("Analysis result",
			zap.Bool("is_safe", result.IsSafe),
			zap.String("message", result.Message),
			zap.Float64("spam_score", result.SpamScore),
			zap.Float64("sentiment_score", result.SentimentScore),
			zap.Any("topic_relevance", result.TopicRelevance),
			zap.Bool("sensitive_content", result.SensitiveContent),
			zap.Strings("entities", result.Entities),
			zap.Int("link_count", result.LinkCount),
			zap.Int("email_count", result.EmailCount))
	}
}



Great question. When setting up email authentication records for a domain and subdomain, you'll need to add records to both, but in slightly different ways. Let's break it down:

For the main domain (hello.com):

SPF record: Add to hello.com
DKIM record: Add to hello.com
DMARC record: Add to hello.com
MX record: Add to hello.com


For the subdomain (smtp.hello.com):

SPF record: Add to smtp.hello.com
DKIM record: Typically not needed, but if used, add to smtp.hello.com
DMARC record: Typically inherits from the main domain, but can be added to smtp.hello.com if needed
MX record: Add to smtp.hello.com if it will receive email directly